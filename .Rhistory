```{r echo=FALSE, fig.height=4, fig.width=4, fig.align='center'}
tmap_mode("view")
```{r echo=FALSE, fig.height=4, fig.width=4, fig.align='center'}
library(coronabr)
library(dplyr)
library(brazilmaps) #usar remotes::install_github("rpradosiqueira/brazilmaps")
library(sf)
library(tmap)
library(htmlwidgets)
dados <- get_corona_br(by_uf = TRUE)
# Pegando a data mais recente com os dados completos
# pode ser a data máxima, ou anterior à máxima
datas <- plyr::count(dados$date[dados$last_available_confirmed > 0
& !is.na(dados$state)])
datas$lag <- datas$freq - dplyr::lag(datas$freq)
if (datas$lag[which.max(datas$x)] < 0) {
data_max <- max(datas$x, na.rm = TRUE) - 1
} else {
data_max <- max(datas$x, na.rm = TRUE)
}
# proporcao de casos por 100k
dados_format <- dados %>%
# renomeia colunas e arredonda casos
mutate(`Casos (por 100 mil hab.)` = round(last_available_confirmed_per_100k_inhabitants),
State = city_ibge_code) %>%
# filtra para ultima data
filter(date == data_max)
# carregando shapefile br
br <- brazilmaps::get_brmap(geo = "State",
class = "sf")
# fazendo o merge dos dados e shapefile
br_sf <- sf::st_as_sf(br) %>%
merge(dados_format, by = "State") %>%
dplyr::relocate(nome)
# mapa
mapa <- tm_shape(br_sf) +
#tm_fill() +
tm_borders() +
tm_symbols(size = "Casos (por 100 mil hab.)",
col = "red",
border.col = "red",
scale = 2,
alpha = 0.5)
mapa + tm_fill(alpha = .7)
tmap_mode("view")
mapa
library(widgetframe)
htmlwidgets::saveWidget(mapa,'leaflet.html')
# mapa
mapa <- tm_shape(br_sf) +
#tm_fill() +
tm_borders() +
tm_symbols(size = "Casos (por 100 mil hab.)",
col = "red",
border.col = "red",
scale = 2,
alpha = 0.7)
tmap_mode("view")
library(coronabr)
library(dplyr)
library(brazilmaps) #usar remotes::install_github("rpradosiqueira/brazilmaps")
library(sf)
library(tmap)
library(htmlwidgets)
dados <- get_corona_br(by_uf = TRUE)
#at <- format_corona_br(dados)
# Pegando a data mais recente com os dados completos
# pode ser a data máxima, ou anterior à máxima
datas <- plyr::count(dados$date[dados$last_available_confirmed > 0
& !is.na(dados$state)])
datas$lag <- datas$freq - dplyr::lag(datas$freq)
if (datas$lag[which.max(datas$x)] < 0) {
data_max <- max(datas$x, na.rm = TRUE) - 1
} else {
data_max <- max(datas$x, na.rm = TRUE)
}
# proporcao de casos por 100k
dados_format <- dados %>%
# renomeia colunas e arredonda casos
mutate(`Casos (por 100 mil hab.)` = round(last_available_confirmed_per_100k_inhabitants),
State = city_ibge_code) %>%
# filtra para ultima data
filter(date == data_max)
# carregando shapefile br
br <- brazilmaps::get_brmap(geo = "State",
class = "sf")
# fazendo o merge dos dados e shapefile
br_sf <- sf::st_as_sf(br) %>%
merge(dados_format, by = "State") %>%
dplyr::relocate(nome)
# mapa
mapa <- tm_shape(br_sf) +
#tm_fill() +
tm_borders() +
tm_symbols(size = "Casos (por 100 mil hab.)",
col = "red",
border.col = "red",
scale = 2,
alpha = 0.7)
library(coronabr)
library(dplyr)
library(brazilmaps) #usar remotes::install_github("rpradosiqueira/brazilmaps")
library(sf)
library(tmap)
library(htmlwidgets)
dados <- get_corona_br(by_uf = TRUE)
#at <- format_corona_br(dados)
# Pegando a data mais recente com os dados completos
# pode ser a data máxima, ou anterior à máxima
datas <- plyr::count(dados$date[dados$last_available_confirmed > 0
& !is.na(dados$state)])
datas$lag <- datas$freq - dplyr::lag(datas$freq)
if (datas$lag[which.max(datas$x)] < 0) {
data_max <- max(datas$x, na.rm = TRUE) - 1
} else {
data_max <- max(datas$x, na.rm = TRUE)
}
# proporcao de casos por 100k
dados_format <- dados %>%
# renomeia colunas e arredonda casos
mutate(`Casos (por 100 mil hab.)` = round(last_available_confirmed_per_100k_inhabitants),
State = city_ibge_code) %>%
# filtra para ultima data
filter(date == data_max)
# carregando shapefile br
br <- brazilmaps::get_brmap(geo = "State",
class = "sf")
# fazendo o merge dos dados e shapefile
br_sf <- sf::st_as_sf(br) %>%
merge(dados_format, by = "State") %>%
dplyr::relocate(nome)
# mapa
mapa <- tm_shape(br_sf) +
#tm_fill() +
tm_borders() +
tm_symbols(size = "Casos (por 100 mil hab.)",
col = "red",
border.col = "red",
scale = 2,
alpha = 0.7)
tmap_mode("view")
# mapa
mapa <- tm_shape(br_sf) +
#tm_fill() +
tm_borders() +
tm_symbols(size = "Casos (por 100 mil hab.)",
col = "red",
border.col = "red",
scale = 2,
alpha = 0.7)
tmap_mode("view")
tmap_mode("view")
mapa + tm_fill(alpha = .7)
tmap_mode("view")
mapa + tm_fill(alpha = .7)
```{r echo=FALSE, fig.height=4, fig.width=4, fig.align='center'}
library(coronabr)
library(dplyr)
library(brazilmaps)
library(sf)
library(tmap)
library(htmlwidgets)
dados <- get_corona_br(by_uf = TRUE)
datas <- plyr::count(dados$date[dados$last_available_confirmed > 0
& !is.na(dados$state)])
datas$lag <- datas$freq - dplyr::lag(datas$freq)
if (datas$lag[which.max(datas$x)] < 0) {
data_max <- max(datas$x, na.rm = TRUE) - 1
} else {
data_max <- max(datas$x, na.rm = TRUE)
}
dados_format <- dados %>%
mutate(`Casos (por 100 mil hab.)` = round(last_available_confirmed_per_100k_inhabitants),
State = city_ibge_code) %>%
filter(date == data_max)
br <- brazilmaps::get_brmap(geo = "State",
class = "sf")
br_sf <- sf::st_as_sf(br) %>%
merge(dados_format, by = "State") %>%
dplyr::relocate(nome)
mapa <- tm_shape(br_sf) +
tm_borders() +
tm_symbols(size = "Casos (por 100 mil hab.)",
col = "red",
border.col = "red",
scale = 2,
alpha = 0.5)
mapa + tm_fill(alpha = .7)
library(coronabr)
library(dplyr)
library(brazilmaps) #usar remotes::install_github("rpradosiqueira/brazilmaps")
library(sf)
library(tmap)
library(htmlwidgets)
dados <- get_corona_br(by_uf = TRUE)
#at <- format_corona_br(dados)
# Pegando a data mais recente com os dados completos
# pode ser a data máxima, ou anterior à máxima
datas <- plyr::count(dados$date[dados$last_available_confirmed > 0
& !is.na(dados$state)])
datas$lag <- datas$freq - dplyr::lag(datas$freq)
if (datas$lag[which.max(datas$x)] < 0) {
data_max <- max(datas$x, na.rm = TRUE) - 1
} else {
data_max <- max(datas$x, na.rm = TRUE)
}
# proporcao de casos por 100k
dados_format <- dados %>%
# renomeia colunas e arredonda casos
mutate(`Casos (por 100 mil hab.)` = round(last_available_confirmed_per_100k_inhabitants),
State = city_ibge_code) %>%
# filtra para ultima data
filter(date == data_max)
# carregando shapefile br
br <- brazilmaps::get_brmap(geo = "State",
class = "sf")
# fazendo o merge dos dados e shapefile
br_sf <- sf::st_as_sf(br) %>%
merge(dados_format, by = "State") %>%
dplyr::relocate(nome)
# mapa
mapa <- tm_shape(br_sf) +
#tm_fill() +
tm_borders() +
tm_symbols(size = "Casos (por 100 mil hab.)",
col = "red",
border.col = "red",
scale = 2,
alpha = 0.5)
mapa + tm_fill(alpha = .7)
tmap_mode("view")
mapa
library(widgetframe)
htmlwidgets::saveWidget(mapa,'leaflet.html')
source("C:/Users/Lucas/Repositorio/Mapa-covid/mapa.R")
library(coronabr)
library(dplyr)
library(brazilmaps) #usar remotes::install_github("rpradosiqueira/brazilmaps")
library(sf)
library(tmap)
library(htmlwidgets)
dados <- get_corona_br(by_uf = TRUE)
#at <- format_corona_br(dados)
# Pegando a data mais recente com os dados completos
# pode ser a data máxima, ou anterior à máxima
datas <- plyr::count(dados$date[dados$last_available_confirmed > 0
& !is.na(dados$state)])
datas$lag <- datas$freq - dplyr::lag(datas$freq)
if (datas$lag[which.max(datas$x)] < 0) {
data_max <- max(datas$x, na.rm = TRUE) - 1
} else {
data_max <- max(datas$x, na.rm = TRUE)
}
# proporcao de casos por 100k
dados_format <- dados %>%
# renomeia colunas e arredonda casos
mutate(`Casos (por 100 mil hab.)` = round(last_available_confirmed_per_100k_inhabitants),
State = city_ibge_code) %>%
# filtra para ultima data
filter(date == data_max)
# carregando shapefile br
br <- brazilmaps::get_brmap(geo = "State",
class = "sf")
# fazendo o merge dos dados e shapefile
br_sf <- sf::st_as_sf(br) %>%
merge(dados_format, by = "State") %>%
dplyr::relocate(nome)
# mapa
mapa <- tm_shape(br_sf) +
#tm_fill() +
tm_borders() +
tm_symbols(size = "Casos (por 100 mil hab.)",
col = "red",
border.col = "red",
scale = 2,
alpha = 0.5)
mapa + tm_fill(alpha = .7)
tmap_mode("view")
mapa
## bibliotecas
library(httr)
library(jsonlite)
library(dplyr)
## api para pegar os dados mais atualizados de Covid-19
read_CityDataCovid <- function() {
# lê a URL da api
url <- "https://brasil.io/api/dataset/covid19/caso/data?format=json"
tf <- GET(url)
content <- content(tf, as = 'text')
content_from_json <- fromJSON(content)
out <- content_from_json$results
# verifica se têm mais páginas de dados e pega todas.
while(!is.null(content_from_json$`next`)){
url <- content_from_json$`next`
tf <- GET(url)
content <- content(tf, as = 'text')
content_from_json <- fromJSON(content)
results_df_np <- content_from_json$results
out <- bind_rows(out, results_df_np)
}
return(out)
}
data_covid19 <- read_CityDataCovid()
# Você pode especificar o estado ou a cidade que quer analisar.
# Os dados estão disponíveis tanto a nível de cidade, quanto de estado, que pode ser definido no argumento place_type
# Na base existe o registro diário do número de casos. Caso queira apenas o mais recente basta filtrar a coluna is_last == TRUE
# Para o exemplo, usaremos os dados mais recentes a nível de cidades, do estado de Santa Catarina.
data_covid19 <- data_covid19 %>% filter(state == "SC",
place_type == "city",
!is.na(city_ibge_code),
confirmed > 0,
## bibliotecas
library(httr)
library(jsonlite)
# Você pode especificar o estado ou a cidade que quer analisar.
# Os dados estão disponíveis tanto a nível de cidade, quanto de estado, que pode ser definido no argumento place_type
# Na base existe o registro diário do número de casos. Caso queira apenas o mais recente basta filtrar a coluna is_last == TRUE
# Para o exemplo, usaremos os dados mais recentes a nível de cidades, do estado de Santa Catarina.
data_covid19 <- data_covid19 %>% filter(state == "SP",
# Primeiro precisamos dos dados de latitude e longitude das cidades analisadas.
urlfile <- "https://raw.githubusercontent.com/kelvins/Municipios-Brasileiros/master/csv/municipios.csv"
cities_lat_lng <- read.csv(urlfile,encoding = "UTF-8", col.names = c("COD_IBGE", "Cidade","lat","lng","Capital","Codigo_UF"))
# Primeiro precisamos dos dados de latitude e longitude das cidades analisadas.
urlfile <- "https://raw.githubusercontent.com/kelvins/Municipios-Brasileiros/master/csv/municipios.csv"
cities_lat_lng <- read.csv(urlfile,encoding = "UTF-8", col.names = c("COD_IBGE", "Cidade","lat","lng","Capital","Codigo_UF"))
## bibliotecas
library(leaflet)
map_cities <- leaflet(data_covid19) %>%
addTiles() %>%
addMarkers(popup = paste0("<b>Cidade: </b>", data_covid19$city,"<br>",
"<b>Casos Confirmados: </b>", data_covid19$confirmed),
label = ~city
group = "addMarkers") %>%
## bibliotecas
library(leaflet)
map_cities <- leaflet(data_covid19) %>%
addTiles() %>%
addMarkers(popup = paste0("<b>Cidade: </b>", data_covid19$city,"<br>",
"<b>Casos Confirmados: </b>", data_covid19$confirmed),
label = ~city
group = "addMarkers") %>%
## bibliotecas
library(leaflet)
map_cities <- leaflet(data_covid19) %>%
addTiles() %>%
addMarkers(popup = paste0("<b>Cidade: </b>", data_covid19$city,"<br>",
"<b>Casos Confirmados: </b>", data_covid19$confirmed),
label = ~city
group = "addMarkers") %>%
## bibliotecas
library(httr)
library(jsonlite)
library(dplyr)
## api para pegar os dados mais atualizados de Covid-19
read_CityDataCovid <- function() {
# lê a URL da api
url <- "https://brasil.io/api/dataset/covid19/caso/data?format=json"
tf <- GET(url)
content <- content(tf, as = 'text')
content_from_json <- fromJSON(content)
out <- content_from_json$results
# verifica se têm mais páginas de dados e pega todas.
while(!is.null(content_from_json$`next`)){
url <- content_from_json$`next`
tf <- GET(url)
content <- content(tf, as = 'text')
content_from_json <- fromJSON(content)
results_df_np <- content_from_json$results
out <- bind_rows(out, results_df_np)
}
return(out)
}
data_covid19 <- read_CityDataCovid()
# Você pode especificar o estado ou a cidade que quer analisar.
# Os dados estão disponíveis tanto a nível de cidade, quanto de estado, que pode ser definido no argumento place_type
# Na base existe o registro diário do número de casos. Caso queira apenas o mais recente basta filtrar a coluna is_last == TRUE
# Para o exemplo, usaremos os dados mais recentes a nível de cidades, do estado de Santa Catarina.
data_covid19 <- data_covid19 %>% filter(state == "SC",
place_type == "city",
!is.na(city_ibge_code),
confirmed > 0,
# Primeiro precisamos dos dados de latitude e longitude das cidades analisadas.
urlfile <- "https://raw.githubusercontent.com/kelvins/Municipios-Brasileiros/master/csv/municipios.csv"
cities_lat_lng <- read.csv(urlfile,encoding = "UTF-8", col.names = c("COD_IBGE", "Cidade","lat","lng","Capital","Codigo_UF"))
# Primeiro precisamos dos dados de latitude e longitude das cidades analisadas.
urlfile <- "https://raw.githubusercontent.com/kelvins/Municipios-Brasileiros/master/csv/municipios.csv"
cities_lat_lng <- read.csv(urlfile,encoding = "UTF-8", col.names = c("COD_IBGE", "Cidade","lat","lng","Capital","Codigo_UF"))
# Primeiro precisamos dos dados de latitude e longitude das cidades analisadas.
urlfile <- "https://raw.githubusercontent.com/kelvins/Municipios-Brasileiros/master/csv/municipios.csv"
cities_lat_lng <- read.csv(urlfile,encoding = "UTF-8", col.names = c("COD_IBGE", "Cidade","lat","lng","Capital","Codigo_UF"))
## bibliotecas
library(leaflet)
map_cities <- leaflet(data_covid19) %>%
addTiles() %>%
addMarkers(popup = paste0("<b>Cidade: </b>", data_covid19$city,"<br>",
"<b>Casos Confirmados: </b>", data_covid19$confirmed),
label = ~city
group = "addMarkers") %>%
## bibliotecas
library(leaflet)
map_cities <- leaflet(data_covid19) %>%
addTiles() %>%
addMarkers(popup = paste0("<b>Cidade: </b>", data_covid19$city,"<br>",
"<b>Casos Confirmados: </b>", data_covid19$confirmed),
label = ~city
group = "addMarkers") %>%
map_total_cases <- leaflet(data_covid19) %>% addTiles() %>%
addProviderTiles(providers$CartoDB.Positron) %>%
addCircleMarkers(
radius = ~sqrt(data_covid19$confirmed),
fillOpacity = 0.5, stroke = F,
popup = paste0("<b>Cidade: </b>", data_covid19$city,"<br>",
"<b>Casos Confirmados: </b>", data_covid19$confirmed),
label = ~city
)
# bibliotecas
library(brazilmaps)
library(sf)
# pegando as geometrias das cidades de Santa Catarina (42)
shp <- get_brmap("City", geo.filter = list(State = 42))
shp$City <- as.character(shp$City)
# definindo que o dataframe contém dados geométricos
shp_sf <- st_as_sf(shp)%>%
st_transform(4326)
#unindo os dados de COVID-19 com as geometrias das cidades.
shp_sf <- shp_sf %>% filter(City %in% data_covid19$city_ibge_code)
shp_sf <- left_join(shp_sf,data_covid19, by = c("City" = "city_ibge_code"))
## define cores para cada conjunto numérico
pal <- colorNumeric(palette = "Reds", domain = shp_sf$confirmed_per_100k_inhabitants)
# heatmap dos casos de covid-19, por 100 mil habitantes, em SC.
map_100k <- leaflet(shp_sf) %>%
addProviderTiles(providers$CartoDB.Positron) %>%
addPolygons(data = shp_sf,
smoothFactor = 0.5,
fillOpacity = 0.5,
weight = 0.5,
color = ~pal(confirmed_per_100k_inhabitants),
opacity = 0.8,
highlightOptions = highlightOptions(color = "black",
weight = 2,
bringToFront = TRUE),
popup = ~paste0(sep = " ",
"<b>Cidade: </b>", city, "<br>",
"<b>Casos confirmados: </b>", confirmed, "<br>",
"<b>Casos por 100k habitantes: </b>", confirmed_per_100k_inhabitants),
label = ~city) %>%
addLegend("bottomright",
title = "Casos confirmados por<br>100k habitantes",
pal = pal,
values = ~confirmed_per_100k_inhabitants,
opacity = 0.8)
#Exportando mapas
htmlwidgets::saveWidget(map_100k,"map_100k.html")
